# Vagas TI - Scraper de Concursos

Este projeto Ã© um pipeline automatizado para coletar, processar e armazenar informaÃ§Ãµes sobre concursos pÃºblicos na Ã¡rea de Tecnologia da InformaÃ§Ã£o (TI). Ele busca dados do site "PCI Concursos", filtra por cargos de interesse, limpa dados expirados e armazena as informaÃ§Ãµes relevantes em um banco de dados MySQL.

## ğŸš€ Funcionalidades

- **Scraper (`scraper.py`)**: Coleta novos concursos do site PCI Concursos, filtrando especificamente por cargos de TI definidos no sistema.
- **Cleaner (`cleaner.py`)**: Remove registros que jÃ¡ expiraram ou que nÃ£o possuem data de inÃ­cio vÃ¡lida, mantendo a base de dados limpa.
- **Database (`database.py`)**: Insere e atualiza as informaÃ§Ãµes no banco de dados MySQL, gerenciando o status dos concursos (Aberto, Encerrado, Cancelado).
- **Orquestrador (`main.py`)**: Gerencia a execuÃ§Ã£o sequencial dos scripts acima, garantindo o fluxo correto de dados.

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8 ou superior
- MySQL Server
- **Importante**: O projeto assume a existÃªncia do diretÃ³rio `/var/www/vagas/data/` para armazenar arquivos JSON temporÃ¡rios (`data.json`, `processed.json`). Certifique-se de que este diretÃ³rio exista e que o usuÃ¡rio que executa o script tenha permissÃµes de escrita nele.

## ğŸ› ï¸ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
   ```bash
   git clone https://github.com/seu-usuario/vagas-ti.git
   cd vagas-ti
   ```

2. **Crie um ambiente virtual (recomendado):**
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # Linux/Mac
   # ou
   venv\Scripts\activate  # Windows
   ```

3. **Instale as dependÃªncias:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Prepare o diretÃ³rio de dados:**
   ```bash
   sudo mkdir -p /var/www/vagas/data
   sudo chown -R $USER:$USER /var/www/vagas/data
   ```

## âš™ï¸ ConfiguraÃ§Ã£o

Crie um arquivo `.env` na raiz do projeto com as credenciais do seu banco de dados MySQL. VocÃª pode usar o modelo abaixo:

```env
DB_HOST=localhost
DB_USER=seu_usuario
DB_PASSWORD=sua_senha
DB_NAME=nome_do_banco
DB_PORT=3306
```

## ğŸ—„ï¸ Estrutura do Banco de Dados

O sistema utiliza uma tabela chamada `concursos`. Execute o seguinte script SQL no seu banco de dados para criÃ¡-la:

```sql
CREATE TABLE IF NOT EXISTS concursos (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    url VARCHAR(255) UNIQUE NOT NULL,
    state VARCHAR(50),
    job VARCHAR(255),
    processed_at DATETIME,
    start_date DATE,
    pdf_url VARCHAR(255),
    status ENUM('Aberto', 'Encerrado', 'Cancelado') DEFAULT 'Aberto',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

## â–¶ï¸ Uso

Para executar o pipeline completo (coleta, limpeza e armazenamento), execute o script principal:

```bash
python main.py
```

O script executarÃ¡ as etapas na seguinte ordem:
1. **Scraper**: Busca novas vagas.
2. **Cleaner**: Limpa vagas expiradas do arquivo local.
3. **Database**: Sincroniza os dados com o banco de dados MySQL.

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ base.py       # DefiniÃ§Ãµes de cargos e constantes
â”‚   â”œâ”€â”€ cleaner.py    # Limpeza de dados locais
â”‚   â”œâ”€â”€ database.py   # InteraÃ§Ã£o com o banco de dados
â”‚   â””â”€â”€ scraper.py    # LÃ³gica de scraping
â”œâ”€â”€ main.py           # Script principal (entry point)
â”œâ”€â”€ requirements.txt  # DependÃªncias do projeto
â”œâ”€â”€ README.md         # DocumentaÃ§Ã£o
â””â”€â”€ .env              # VariÃ¡veis de ambiente (nÃ£o versionado)
```

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou enviar pull requests.

## License

[MIT](https://choosealicense.com/licenses/mit/)
